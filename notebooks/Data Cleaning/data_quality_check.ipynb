{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25046703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NYC YELLOW TAXI DATA - COMPREHENSIVE QUALITY ASSESSMENT\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# NYC Yellow Taxi Analytics - Data Quality Assessment\n",
    "# This notebook performs comprehensive data quality checks on the taxi trip data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NYC YELLOW TAXI DATA - COMPREHENSIVE QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d64c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ DISCOVERED FILES\n",
      "================================================================================\n",
      "Total parquet files found: 44\n",
      "\n",
      "2022: 12 files\n",
      "  - yellow_tripdata_2022-01.parquet\n",
      "  - yellow_tripdata_2022-02.parquet\n",
      "  - yellow_tripdata_2022-03.parquet\n",
      "  ... and 9 more\n",
      "\n",
      "2023: 12 files\n",
      "  - yellow_tripdata_2023-01.parquet\n",
      "  - yellow_tripdata_2023-02.parquet\n",
      "  - yellow_tripdata_2023-03.parquet\n",
      "  ... and 9 more\n",
      "\n",
      "2024: 12 files\n",
      "  - yellow_tripdata_2024-01.parquet\n",
      "  - yellow_tripdata_2024-02.parquet\n",
      "  - yellow_tripdata_2024-03.parquet\n",
      "  ... and 9 more\n",
      "\n",
      "2025: 8 files\n",
      "  - yellow_tripdata_2025-01.parquet\n",
      "  - yellow_tripdata_2025-02.parquet\n",
      "  - yellow_tripdata_2025-03.parquet\n",
      "  ... and 5 more\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. DATA DISCOVERY - Find all parquet files\n",
    "\n",
    "data_path = '/Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/data/raw/'\n",
    "\n",
    "# Find all parquet files across all years\n",
    "all_files = []\n",
    "for year in ['2022', '2023', '2024', '2025']:\n",
    "    year_path = os.path.join(data_path, year)\n",
    "    if os.path.exists(year_path):\n",
    "        files = glob(os.path.join(year_path, '*.parquet'))\n",
    "        all_files.extend(files)\n",
    "\n",
    "print(f\"\\nüìÅ DISCOVERED FILES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total parquet files found: {len(all_files)}\")\n",
    "\n",
    "# Organize by year\n",
    "files_by_year = {}\n",
    "for file in sorted(all_files):\n",
    "    year = file.split('/')[-2]\n",
    "    if year not in files_by_year:\n",
    "        files_by_year[year] = []\n",
    "    files_by_year[year].append(os.path.basename(file))\n",
    "\n",
    "for year, files in sorted(files_by_year.items()):\n",
    "    print(f\"\\n{year}: {len(files)} files\")\n",
    "    for f in files[:3]:  # Show first 3 files\n",
    "        print(f\"  - {f}\")\n",
    "    if len(files) > 3:\n",
    "        print(f\"  ... and {len(files) - 3} more\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe4a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìä LOADING SAMPLE DATA FROM EACH YEAR\n",
      "================================================================================\n",
      "\n",
      "2022:\n",
      "  File: yellow_tripdata_2022-01.parquet\n",
      "  Rows: 2,463,931\n",
      "  Columns: 19\n",
      "  File Size: 36.37 MB\n",
      "  Memory Usage: 454.09 MB\n",
      "\n",
      "2022:\n",
      "  File: yellow_tripdata_2022-01.parquet\n",
      "  Rows: 2,463,931\n",
      "  Columns: 19\n",
      "  File Size: 36.37 MB\n",
      "  Memory Usage: 454.09 MB\n",
      "\n",
      "2023:\n",
      "  File: yellow_tripdata_2023-01.parquet\n",
      "  Rows: 3,066,766\n",
      "  Columns: 19\n",
      "  File Size: 45.46 MB\n",
      "  Memory Usage: 565.61 MB\n",
      "\n",
      "2023:\n",
      "  File: yellow_tripdata_2023-01.parquet\n",
      "  Rows: 3,066,766\n",
      "  Columns: 19\n",
      "  File Size: 45.46 MB\n",
      "  Memory Usage: 565.61 MB\n",
      "\n",
      "2024:\n",
      "  File: yellow_tripdata_2024-01.parquet\n",
      "  Rows: 2,964,624\n",
      "  Columns: 19\n",
      "  File Size: 47.65 MB\n",
      "  Memory Usage: 511.09 MB\n",
      "\n",
      "2024:\n",
      "  File: yellow_tripdata_2024-01.parquet\n",
      "  Rows: 2,964,624\n",
      "  Columns: 19\n",
      "  File Size: 47.65 MB\n",
      "  Memory Usage: 511.09 MB\n",
      "\n",
      "2025:\n",
      "  File: yellow_tripdata_2025-01.parquet\n",
      "  Rows: 3,475,226\n",
      "  Columns: 20\n",
      "  File Size: 56.42 MB\n",
      "  Memory Usage: 616.31 MB\n",
      "\n",
      "‚úÖ Using 2025 data for detailed quality checks\n",
      "\n",
      "2025:\n",
      "  File: yellow_tripdata_2025-01.parquet\n",
      "  Rows: 3,475,226\n",
      "  Columns: 20\n",
      "  File Size: 56.42 MB\n",
      "  Memory Usage: 616.31 MB\n",
      "\n",
      "‚úÖ Using 2025 data for detailed quality checks\n"
     ]
    }
   ],
   "source": [
    "# 2. LOAD SAMPLE DATA - Load one file from each year for quality check\n",
    "\n",
    "print(\"\\n\\nüìä LOADING SAMPLE DATA FROM EACH YEAR\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample_data = {}\n",
    "for year in files_by_year.keys():\n",
    "    try:\n",
    "        # Load first file from each year\n",
    "        file_path = os.path.join(data_path, year, files_by_year[year][0])\n",
    "        df_sample = pd.read_parquet(file_path)\n",
    "        sample_data[year] = df_sample\n",
    "        \n",
    "        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"\\n{year}:\")\n",
    "        print(f\"  File: {files_by_year[year][0]}\")\n",
    "        print(f\"  Rows: {len(df_sample):,}\")\n",
    "        print(f\"  Columns: {len(df_sample.columns)}\")\n",
    "        print(f\"  File Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"  Memory Usage: {df_sample.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{year}: ‚ùå Error loading - {str(e)}\")\n",
    "\n",
    "# Use most recent year for detailed analysis\n",
    "latest_year = max(sample_data.keys())\n",
    "df = sample_data[latest_year]\n",
    "print(f\"\\n‚úÖ Using {latest_year} data for detailed quality checks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0453b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìã SCHEMA VALIDATION\n",
      "================================================================================\n",
      "\n",
      "‚úì Column Presence Check:\n",
      "  ‚ÑπÔ∏è  Extra columns: {'cbd_congestion_fee'}\n",
      "\n",
      "‚úì Column Count: 20\n",
      "\n",
      "‚úì Column Names and Data Types:\n",
      "  VendorID                       | int32           | Nulls:  0.00%\n",
      "  tpep_pickup_datetime           | datetime64[us]  | Nulls:  0.00%\n",
      "  tpep_dropoff_datetime          | datetime64[us]  | Nulls:  0.00%\n",
      "  passenger_count                | float64         | Nulls: 15.54%\n",
      "  trip_distance                  | float64         | Nulls:  0.00%\n",
      "  RatecodeID                     | float64         | Nulls: 15.54%\n",
      "  store_and_fwd_flag             | object          | Nulls: 15.54%\n",
      "  PULocationID                   | int32           | Nulls:  0.00%\n",
      "  DOLocationID                   | int32           | Nulls:  0.00%\n",
      "  payment_type                   | int64           | Nulls:  0.00%\n",
      "  fare_amount                    | float64         | Nulls:  0.00%\n",
      "  extra                          | float64         | Nulls:  0.00%\n",
      "  mta_tax                        | float64         | Nulls:  0.00%\n",
      "  tip_amount                     | float64         | Nulls:  0.00%\n",
      "  tolls_amount                   | float64         | Nulls:  0.00%\n",
      "  improvement_surcharge          | float64         | Nulls:  0.00%\n",
      "  total_amount                   | float64         | Nulls:  0.00%\n",
      "  congestion_surcharge           | float64         | Nulls: 15.54%\n",
      "  Airport_fee                    | float64         | Nulls: 15.54%\n",
      "  cbd_congestion_fee             | float64         | Nulls:  0.00%\n",
      "  store_and_fwd_flag             | object          | Nulls: 15.54%\n",
      "  PULocationID                   | int32           | Nulls:  0.00%\n",
      "  DOLocationID                   | int32           | Nulls:  0.00%\n",
      "  payment_type                   | int64           | Nulls:  0.00%\n",
      "  fare_amount                    | float64         | Nulls:  0.00%\n",
      "  extra                          | float64         | Nulls:  0.00%\n",
      "  mta_tax                        | float64         | Nulls:  0.00%\n",
      "  tip_amount                     | float64         | Nulls:  0.00%\n",
      "  tolls_amount                   | float64         | Nulls:  0.00%\n",
      "  improvement_surcharge          | float64         | Nulls:  0.00%\n",
      "  total_amount                   | float64         | Nulls:  0.00%\n",
      "  congestion_surcharge           | float64         | Nulls: 15.54%\n",
      "  Airport_fee                    | float64         | Nulls: 15.54%\n",
      "  cbd_congestion_fee             | float64         | Nulls:  0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. SCHEMA VALIDATION - Check column structure\n",
    "\n",
    "print(\"\\n\\nüìã SCHEMA VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Expected columns based on data dictionary\n",
    "expected_columns = [\n",
    "    'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "    'passenger_count', 'trip_distance', 'RatecodeID',\n",
    "    'store_and_fwd_flag', 'PULocationID', 'DOLocationID',\n",
    "    'payment_type', 'fare_amount', 'extra', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "    'total_amount', 'congestion_surcharge', 'Airport_fee'\n",
    "]\n",
    "\n",
    "print(\"\\n‚úì Column Presence Check:\")\n",
    "actual_columns = df.columns.tolist()\n",
    "missing_columns = set(expected_columns) - set(actual_columns)\n",
    "extra_columns = set(actual_columns) - set(expected_columns)\n",
    "\n",
    "if not missing_columns and not extra_columns:\n",
    "    print(\"  ‚úÖ All expected columns present, no extra columns\")\n",
    "else:\n",
    "    if missing_columns:\n",
    "        print(f\"  ‚ö†Ô∏è  Missing columns: {missing_columns}\")\n",
    "    if extra_columns:\n",
    "        print(f\"  ‚ÑπÔ∏è  Extra columns: {extra_columns}\")\n",
    "\n",
    "print(f\"\\n‚úì Column Count: {len(actual_columns)}\")\n",
    "print(f\"\\n‚úì Column Names and Data Types:\")\n",
    "for col in actual_columns:\n",
    "    dtype = df[col].dtype\n",
    "    null_pct = (df[col].isna().sum() / len(df)) * 100\n",
    "    print(f\"  {col:30s} | {str(dtype):15s} | Nulls: {null_pct:5.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0692fa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üîç DATA QUALITY METRICS\n",
      "================================================================================\n",
      "\n",
      "‚úì Dataset Overview:\n",
      "  Total Records: 3,475,226\n",
      "  Date Range: 2024-12-31 20:47:55 to 2025-02-01 00:00:44\n",
      "  Unique Pickup Locations: 261\n",
      "  Unique Dropoff Locations: 260\n",
      "\n",
      "‚úì Missing Values Analysis:\n",
      "              Column  Missing_Count  Missing_Percentage\n",
      "         Airport_fee         540149               15.54\n",
      "     passenger_count         540149               15.54\n",
      "congestion_surcharge         540149               15.54\n",
      "          RatecodeID         540149               15.54\n",
      "  store_and_fwd_flag         540149               15.54\n",
      "              Column  Missing_Count  Missing_Percentage\n",
      "         Airport_fee         540149               15.54\n",
      "     passenger_count         540149               15.54\n",
      "congestion_surcharge         540149               15.54\n",
      "          RatecodeID         540149               15.54\n",
      "  store_and_fwd_flag         540149               15.54\n",
      "\n",
      "‚úì Duplicate Records: 0 (0.00%)\n",
      "\n",
      "‚úì Duplicate Records: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. DATA QUALITY METRICS\n",
    "\n",
    "print(\"\\n\\nüîç DATA QUALITY METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\n‚úì Dataset Overview:\")\n",
    "print(f\"  Total Records: {len(df):,}\")\n",
    "print(f\"  Date Range: {df['tpep_pickup_datetime'].min()} to {df['tpep_pickup_datetime'].max()}\")\n",
    "print(f\"  Unique Pickup Locations: {df['PULocationID'].nunique()}\")\n",
    "print(f\"  Unique Dropoff Locations: {df['DOLocationID'].nunique()}\")\n",
    "\n",
    "# Missing values analysis\n",
    "print(f\"\\n‚úì Missing Values Analysis:\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isna().sum(),\n",
    "    'Missing_Percentage': (df.isna().sum() / len(df)) * 100\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "critical_missing = missing_summary[missing_summary['Missing_Percentage'] > 0]\n",
    "if len(critical_missing) > 0:\n",
    "    print(critical_missing.to_string(index=False))\n",
    "else:\n",
    "    print(\"  ‚úÖ No missing values detected\")\n",
    "\n",
    "# Duplicate records\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\n‚úì Duplicate Records: {duplicate_count:,} ({(duplicate_count/len(df)*100):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb105d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚ö†Ô∏è  DATA ANOMALY DETECTION\n",
      "================================================================================\n",
      "\n",
      "1. Negative/Zero Value Checks:\n",
      "  Negative/Zero Fares: 145,516\n",
      "  Negative Distance: 0\n",
      "  Zero Distance: 90,893 (2.62%)\n",
      "  Zero/Negative Passengers: 24,656\n",
      "\n",
      "2. Unrealistic Value Checks:\n",
      "  Fares > $500: 55\n",
      "  Distance > 100 miles: 162\n",
      "  Passengers > 6: 18\n",
      "\n",
      "3. Time-Based Anomalies:\n",
      "  Negative Duration: 124\n",
      "  Zero Duration: 1,927\n",
      "  Duration > 3 hours: 1,377\n",
      "\n",
      "4. Total Amount Validation:\n",
      "  Total Amount Mismatches: 2,564,189 (73.78%)\n",
      "\n",
      "üìä TOTAL ANOMALIES DETECTED: 2,828,917 (81.40% of records)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. DATA ANOMALY DETECTION\n",
    "\n",
    "print(\"\\n\\n‚ö†Ô∏è  DATA ANOMALY DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "anomalies = {}\n",
    "\n",
    "# 1. Negative or zero values where they shouldn't be\n",
    "print(\"\\n1. Negative/Zero Value Checks:\")\n",
    "anomalies['negative_fare'] = (df['fare_amount'] <= 0).sum()\n",
    "anomalies['negative_distance'] = (df['trip_distance'] < 0).sum()\n",
    "anomalies['zero_distance'] = (df['trip_distance'] == 0).sum()\n",
    "anomalies['negative_passenger'] = (df['passenger_count'] <= 0).sum()\n",
    "\n",
    "print(f\"  Negative/Zero Fares: {anomalies['negative_fare']:,}\")\n",
    "print(f\"  Negative Distance: {anomalies['negative_distance']:,}\")\n",
    "print(f\"  Zero Distance: {anomalies['zero_distance']:,} ({(anomalies['zero_distance']/len(df)*100):.2f}%)\")\n",
    "print(f\"  Zero/Negative Passengers: {anomalies['negative_passenger']:,}\")\n",
    "\n",
    "# 2. Unrealistic values\n",
    "print(\"\\n2. Unrealistic Value Checks:\")\n",
    "anomalies['extreme_fare'] = (df['fare_amount'] > 500).sum()\n",
    "anomalies['extreme_distance'] = (df['trip_distance'] > 100).sum()\n",
    "anomalies['extreme_passengers'] = (df['passenger_count'] > 6).sum()\n",
    "\n",
    "print(f\"  Fares > $500: {anomalies['extreme_fare']:,}\")\n",
    "print(f\"  Distance > 100 miles: {anomalies['extreme_distance']:,}\")\n",
    "print(f\"  Passengers > 6: {anomalies['extreme_passengers']:,}\")\n",
    "\n",
    "# 3. Time-based anomalies\n",
    "df['trip_duration_minutes'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "anomalies['negative_duration'] = (df['trip_duration_minutes'] < 0).sum()\n",
    "anomalies['zero_duration'] = (df['trip_duration_minutes'] == 0).sum()\n",
    "anomalies['extreme_duration'] = (df['trip_duration_minutes'] > 180).sum()  # > 3 hours\n",
    "\n",
    "print(f\"\\n3. Time-Based Anomalies:\")\n",
    "print(f\"  Negative Duration: {anomalies['negative_duration']:,}\")\n",
    "print(f\"  Zero Duration: {anomalies['zero_duration']:,}\")\n",
    "print(f\"  Duration > 3 hours: {anomalies['extreme_duration']:,}\")\n",
    "\n",
    "# 4. Total amount validation\n",
    "df['calculated_total'] = (df['fare_amount'] + df['extra'] + df['mta_tax'] + \n",
    "                          df['tip_amount'] + df['tolls_amount'] + \n",
    "                          df['improvement_surcharge'] + df['congestion_surcharge'].fillna(0) + \n",
    "                          df['Airport_fee'].fillna(0))\n",
    "df['total_mismatch'] = abs(df['total_amount'] - df['calculated_total']) > 0.10  # 10 cent tolerance\n",
    "anomalies['total_mismatch'] = df['total_mismatch'].sum()\n",
    "\n",
    "print(f\"\\n4. Total Amount Validation:\")\n",
    "print(f\"  Total Amount Mismatches: {anomalies['total_mismatch']:,} ({(anomalies['total_mismatch']/len(df)*100):.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "total_anomalies = sum(anomalies.values())\n",
    "print(f\"\\nüìä TOTAL ANOMALIES DETECTED: {total_anomalies:,} ({(total_anomalies/len(df)*100):.2f}% of records)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e042b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìà STATISTICAL SUMMARY - KEY METRICS\n",
      "================================================================================\n",
      "\n",
      "üí∞ Fare Amount:\n",
      "count   3475226.00\n",
      "mean         17.08\n",
      "std         463.47\n",
      "min        -900.00\n",
      "25%           8.60\n",
      "50%          12.11\n",
      "75%          19.50\n",
      "max      863372.12\n",
      "Name: fare_amount, dtype: float64\n",
      "\n",
      "üìè Trip Distance:\n",
      "count   3475226.00\n",
      "mean          5.86\n",
      "std         564.60\n",
      "min           0.00\n",
      "25%           0.98\n",
      "50%           1.67\n",
      "75%           3.10\n",
      "max      276423.57\n",
      "Name: trip_distance, dtype: float64\n",
      "\n",
      "üë• Passenger Count:\n",
      "passenger_count\n",
      "0.00      24656\n",
      "1.00    2322434\n",
      "2.00     407761\n",
      "3.00      91409\n",
      "4.00      59009\n",
      "5.00      17786\n",
      "6.00      12004\n",
      "7.00          4\n",
      "8.00         11\n",
      "9.00          3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üí≥ Payment Type Distribution:\n",
      "  Credit Card: 2,444,393 (70.34%)\n",
      "  Unknown (0): 540,149 (15.54%)\n",
      "  Cash: 390,429 (11.23%)\n",
      "  Dispute: 76,481 (2.20%)\n",
      "  No Charge: 23,773 (0.68%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üöï Rate Code Distribution:\n",
      "  Standard: 2,756,472 (79.32%)\n",
      "  JFK: 94,420 (2.72%)\n",
      "  Unknown (99.0): 41,963 (1.21%)\n",
      "  Negotiated: 26,501 (0.76%)\n",
      "  Newark: 8,622 (0.25%)\n",
      "  Nassau/Westchester: 7,092 (0.20%)\n",
      "  Group Ride: 7 (0.00%)\n",
      "\n",
      "‚è±Ô∏è  Trip Duration (minutes):\n",
      "count   3475226.00\n",
      "mean         15.02\n",
      "std          38.71\n",
      "min      -51472.32\n",
      "25%           7.28\n",
      "50%          11.70\n",
      "75%          18.33\n",
      "max        5626.32\n",
      "Name: trip_duration_minutes, dtype: float64\n",
      "count   3475226.00\n",
      "mean          5.86\n",
      "std         564.60\n",
      "min           0.00\n",
      "25%           0.98\n",
      "50%           1.67\n",
      "75%           3.10\n",
      "max      276423.57\n",
      "Name: trip_distance, dtype: float64\n",
      "\n",
      "üë• Passenger Count:\n",
      "passenger_count\n",
      "0.00      24656\n",
      "1.00    2322434\n",
      "2.00     407761\n",
      "3.00      91409\n",
      "4.00      59009\n",
      "5.00      17786\n",
      "6.00      12004\n",
      "7.00          4\n",
      "8.00         11\n",
      "9.00          3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üí≥ Payment Type Distribution:\n",
      "  Credit Card: 2,444,393 (70.34%)\n",
      "  Unknown (0): 540,149 (15.54%)\n",
      "  Cash: 390,429 (11.23%)\n",
      "  Dispute: 76,481 (2.20%)\n",
      "  No Charge: 23,773 (0.68%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üöï Rate Code Distribution:\n",
      "  Standard: 2,756,472 (79.32%)\n",
      "  JFK: 94,420 (2.72%)\n",
      "  Unknown (99.0): 41,963 (1.21%)\n",
      "  Negotiated: 26,501 (0.76%)\n",
      "  Newark: 8,622 (0.25%)\n",
      "  Nassau/Westchester: 7,092 (0.20%)\n",
      "  Group Ride: 7 (0.00%)\n",
      "\n",
      "‚è±Ô∏è  Trip Duration (minutes):\n",
      "count   3475226.00\n",
      "mean         15.02\n",
      "std          38.71\n",
      "min      -51472.32\n",
      "25%           7.28\n",
      "50%          11.70\n",
      "75%          18.33\n",
      "max        5626.32\n",
      "Name: trip_duration_minutes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. STATISTICAL SUMMARY\n",
    "\n",
    "print(\"\\n\\nüìà STATISTICAL SUMMARY - KEY METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fare statistics\n",
    "print(\"\\nüí∞ Fare Amount:\")\n",
    "print(df['fare_amount'].describe())\n",
    "\n",
    "# Distance statistics\n",
    "print(\"\\nüìè Trip Distance:\")\n",
    "print(df['trip_distance'].describe())\n",
    "\n",
    "# Passenger count\n",
    "print(\"\\nüë• Passenger Count:\")\n",
    "print(df['passenger_count'].value_counts().sort_index())\n",
    "\n",
    "# Payment type\n",
    "print(\"\\nüí≥ Payment Type Distribution:\")\n",
    "payment_labels = {1: 'Credit Card', 2: 'Cash', 3: 'No Charge', 4: 'Dispute', 5: 'Unknown', 6: 'Voided'}\n",
    "payment_dist = df['payment_type'].value_counts()\n",
    "for payment_id, count in payment_dist.items():\n",
    "    label = payment_labels.get(payment_id, f'Unknown ({payment_id})')\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Rate code\n",
    "print(\"\\nüöï Rate Code Distribution:\")\n",
    "rate_labels = {1: 'Standard', 2: 'JFK', 3: 'Newark', 4: 'Nassau/Westchester', 5: 'Negotiated', 6: 'Group Ride'}\n",
    "rate_dist = df['RatecodeID'].value_counts()\n",
    "for rate_id, count in rate_dist.items():\n",
    "    label = rate_labels.get(rate_id, f'Unknown ({rate_id})')\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Trip duration\n",
    "print(\"\\n‚è±Ô∏è  Trip Duration (minutes):\")\n",
    "print(df['trip_duration_minutes'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41fb570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚úÖ BUSINESS LOGIC VALIDATION\n",
      "================================================================================\n",
      "\n",
      "üí° Tip Analysis (Credit Card Payments Only):\n",
      "  Credit Card Trips: 2,444,393 (70.34%)\n",
      "  Trips with Tips: 2,300,221\n",
      "  Average Tip %: inf%\n",
      "  Median Tip %: 27.04%\n",
      "\n",
      "üíµ Revenue per Mile:\n",
      "  Mean: $13.70\n",
      "  Median: $7.10\n",
      "\n",
      "‚è∞ Revenue per Minute:\n",
      "  Mean: $3.24\n",
      "  Median: $1.15\n",
      "\n",
      "üí° Tip Analysis (Credit Card Payments Only):\n",
      "  Credit Card Trips: 2,444,393 (70.34%)\n",
      "  Trips with Tips: 2,300,221\n",
      "  Average Tip %: inf%\n",
      "  Median Tip %: 27.04%\n",
      "\n",
      "üíµ Revenue per Mile:\n",
      "  Mean: $13.70\n",
      "  Median: $7.10\n",
      "\n",
      "‚è∞ Revenue per Minute:\n",
      "  Mean: $3.24\n",
      "  Median: $1.15\n",
      "\n",
      "‚úàÔ∏è  Airport Trips:\n",
      "  Count: 103,042 (2.97%)\n",
      "  Average Fare: $64.94\n",
      "  Average Distance: 16.94 miles\n",
      "\n",
      "‚úàÔ∏è  Airport Trips:\n",
      "  Count: 103,042 (2.97%)\n",
      "  Average Fare: $64.94\n",
      "  Average Distance: 16.94 miles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. BUSINESS LOGIC VALIDATION\n",
    "\n",
    "print(\"\\n\\n‚úÖ BUSINESS LOGIC VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Tip percentage analysis (credit card only)\n",
    "credit_card_trips = df[df['payment_type'] == 1].copy()\n",
    "credit_card_trips['tip_percentage'] = (credit_card_trips['tip_amount'] / credit_card_trips['fare_amount']) * 100\n",
    "\n",
    "print(\"\\nüí° Tip Analysis (Credit Card Payments Only):\")\n",
    "print(f\"  Credit Card Trips: {len(credit_card_trips):,} ({(len(credit_card_trips)/len(df)*100):.2f}%)\")\n",
    "print(f\"  Trips with Tips: {(credit_card_trips['tip_amount'] > 0).sum():,}\")\n",
    "print(f\"  Average Tip %: {credit_card_trips['tip_percentage'].mean():.2f}%\")\n",
    "print(f\"  Median Tip %: {credit_card_trips['tip_percentage'].median():.2f}%\")\n",
    "\n",
    "# Revenue per mile\n",
    "df['revenue_per_mile'] = df['fare_amount'] / df['trip_distance'].replace(0, np.nan)\n",
    "print(f\"\\nüíµ Revenue per Mile:\")\n",
    "print(f\"  Mean: ${df['revenue_per_mile'].mean():.2f}\")\n",
    "print(f\"  Median: ${df['revenue_per_mile'].median():.2f}\")\n",
    "\n",
    "# Revenue per minute\n",
    "df['revenue_per_minute'] = df['fare_amount'] / df['trip_duration_minutes'].replace(0, np.nan)\n",
    "print(f\"\\n‚è∞ Revenue per Minute:\")\n",
    "print(f\"  Mean: ${df['revenue_per_minute'].mean():.2f}\")\n",
    "print(f\"  Median: ${df['revenue_per_minute'].median():.2f}\")\n",
    "\n",
    "# Airport trips analysis\n",
    "airport_trips = df[df['RatecodeID'].isin([2, 3])]\n",
    "print(f\"\\n‚úàÔ∏è  Airport Trips:\")\n",
    "print(f\"  Count: {len(airport_trips):,} ({(len(airport_trips)/len(df)*100):.2f}%)\")\n",
    "print(f\"  Average Fare: ${airport_trips['fare_amount'].mean():.2f}\")\n",
    "print(f\"  Average Distance: {airport_trips['trip_distance'].mean():.2f} miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fd8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "‚≠ê DATA QUALITY SCORE\n",
      "================================================================================\n",
      "\n",
      "Quality Dimensions:\n",
      "  ‚úÖ Completeness: 96.78%\n",
      "  ‚úÖ Uniqueness: 100.00%\n",
      "  ‚ùå Validity: 18.60%\n",
      "  ‚ùå Consistency: 26.22%\n",
      "\n",
      "üéØ OVERALL DATA QUALITY SCORE: 60.40%\n",
      "   ‚ùå Fair - Significant cleaning required\n",
      "\n",
      "Quality Dimensions:\n",
      "  ‚úÖ Completeness: 96.78%\n",
      "  ‚úÖ Uniqueness: 100.00%\n",
      "  ‚ùå Validity: 18.60%\n",
      "  ‚ùå Consistency: 26.22%\n",
      "\n",
      "üéØ OVERALL DATA QUALITY SCORE: 60.40%\n",
      "   ‚ùå Fair - Significant cleaning required\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. DATA QUALITY SCORE CALCULATION\n",
    "\n",
    "print(\"\\n\\n‚≠ê DATA QUALITY SCORE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "quality_metrics = {\n",
    "    'Completeness': 100 - (df.isna().sum().sum() / (len(df) * len(df.columns)) * 100),\n",
    "    'Uniqueness': 100 - (duplicate_count / len(df) * 100),\n",
    "    'Validity': 100 - (total_anomalies / len(df) * 100),\n",
    "    'Consistency': 100 - (anomalies['total_mismatch'] / len(df) * 100),\n",
    "}\n",
    "\n",
    "print(\"\\nQuality Dimensions:\")\n",
    "for metric, score in quality_metrics.items():\n",
    "    status = \"‚úÖ\" if score >= 95 else \"‚ö†Ô∏è \" if score >= 90 else \"‚ùå\"\n",
    "    print(f\"  {status} {metric}: {score:.2f}%\")\n",
    "\n",
    "overall_quality = np.mean(list(quality_metrics.values()))\n",
    "print(f\"\\nüéØ OVERALL DATA QUALITY SCORE: {overall_quality:.2f}%\")\n",
    "\n",
    "if overall_quality >= 95:\n",
    "    print(\"   ‚úÖ Excellent - Data is ready for analysis\")\n",
    "elif overall_quality >= 90:\n",
    "    print(\"   ‚ö†Ô∏è  Good - Minor cleaning recommended\")\n",
    "else:\n",
    "    print(\"   ‚ùå Fair - Significant cleaning required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce11bd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìù RECOMMENDATIONS & ACTION ITEMS\n",
      "================================================================================\n",
      "\n",
      "Action Items:\n",
      "‚Ä¢ Remove/investigate 90,893 trips with zero distance\n",
      "‚Ä¢ Remove 145,516 trips with negative fares\n",
      "‚Ä¢ Investigate 2,564,189 total amount calculation mismatches\n",
      "\n",
      "================================================================================\n",
      "‚úÖ DATA QUALITY ASSESSMENT COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. RECOMMENDATIONS & ACTION ITEMS\n",
    "\n",
    "print(\"\\n\\nüìù RECOMMENDATIONS & ACTION ITEMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "if anomalies['zero_distance'] > len(df) * 0.01:  # > 1%\n",
    "    recommendations.append(f\"‚Ä¢ Remove/investigate {anomalies['zero_distance']:,} trips with zero distance\")\n",
    "\n",
    "if anomalies['negative_fare'] > 0:\n",
    "    recommendations.append(f\"‚Ä¢ Remove {anomalies['negative_fare']:,} trips with negative fares\")\n",
    "\n",
    "if anomalies['extreme_duration'] > len(df) * 0.001:  # > 0.1%\n",
    "    recommendations.append(f\"‚Ä¢ Cap/investigate {anomalies['extreme_duration']:,} trips with duration > 3 hours\")\n",
    "\n",
    "if anomalies['total_mismatch'] > len(df) * 0.05:  # > 5%\n",
    "    recommendations.append(f\"‚Ä¢ Investigate {anomalies['total_mismatch']:,} total amount calculation mismatches\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    recommendations.append(f\"‚Ä¢ Remove {duplicate_count:,} duplicate records\")\n",
    "\n",
    "if len(recommendations) == 0:\n",
    "    print(\"\\n‚úÖ No critical issues found! Data is in good shape for analysis.\")\n",
    "else:\n",
    "    print(\"\\nAction Items:\")\n",
    "    for rec in recommendations:\n",
    "        print(rec)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ DATA QUALITY ASSESSMENT COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee5a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üî¨ DETAILED ANOMALY INVESTIGATION\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£ ZERO DISTANCE TRIPS ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total Zero Distance Trips: 90,893\n",
      "\n",
      "üìä Sample of Zero Distance Trips (First 20):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:49:48   2025-01-01 00:49:48            87           264           0.00        20.06         20.06             2                   0.00\n",
      " 2025-01-01 00:37:43   2025-01-01 00:37:53           148           148           0.00        12.00         17.50             1                   0.17\n",
      " 2025-01-01 00:57:08   2025-01-01 00:57:16           141           141           0.00        30.00         33.50             1                   0.13\n",
      " 2025-01-01 00:27:40   2025-01-01 00:59:30           168            76           0.00        50.50         58.94             1                  31.83\n",
      " 2025-01-01 00:56:49   2025-01-01 00:56:54           164           164           0.00        20.00         30.55             1                   0.08\n",
      " 2025-01-01 00:42:42   2025-01-01 00:42:44           261           261           0.00         3.00         10.35             1                   0.03\n",
      " 2025-01-01 00:43:22   2025-01-01 00:46:18            48            48           0.00         5.00          9.00             1                   2.93\n",
      " 2025-01-01 00:24:26   2025-01-01 00:24:34            60            60           0.00        20.00         25.20             1                   0.13\n",
      " 2025-01-01 00:14:57   2025-01-01 00:17:44            79            79           0.00         3.00          8.00             3                   2.78\n",
      " 2025-01-01 00:49:10   2025-01-01 00:49:14           143           143           0.00        85.00        115.05             1                   0.07\n",
      " 2025-01-01 00:16:07   2025-01-01 00:16:18           226           226           0.00         3.00          5.50             2                   0.18\n",
      " 2025-01-01 00:34:58   2025-01-01 01:09:03            78           139           0.00        53.50         61.94             1                  34.08\n",
      " 2025-01-01 00:22:03   2025-01-01 00:24:00           237           237           0.00         3.70         10.40             1                   1.95\n",
      " 2025-01-01 00:37:13   2025-01-01 01:26:20            49           247           0.00        40.50         42.00             1                  49.12\n",
      " 2025-01-01 00:50:01   2025-01-01 00:50:14           140           140           0.00         3.00          8.00             2                   0.22\n",
      " 2025-01-01 00:24:03   2025-01-01 00:24:06           161           161           0.00        79.00         82.50             2                   0.05\n",
      " 2025-01-01 00:26:16   2025-01-01 00:26:20           161           161           0.00        79.50         88.00             1                   0.07\n",
      " 2025-01-01 00:13:46   2025-01-01 00:29:45           234           231           0.00        13.50         22.20             1                  15.98\n",
      " 2025-01-01 00:32:18   2025-01-01 00:39:23           231           158           0.00         7.20         13.20             1                   7.08\n",
      " 2025-01-01 00:45:42   2025-01-01 01:23:00           158           262           0.00        28.90         36.90             1                  37.30\n",
      "\n",
      "üìà Zero Distance Trip Statistics:\n",
      "  Average Fare: $17.66\n",
      "  Median Fare: $13.31\n",
      "  Average Total: $23.37\n",
      "  Average Duration: 11.68 minutes\n",
      "\n",
      "üí≥ Payment Type Distribution (Zero Distance):\n",
      "  Unknown (0): 51,983 (57.19%)\n",
      "  Credit Card: 19,649 (21.62%)\n",
      "  Cash: 8,926 (9.82%)\n",
      "  Dispute: 5,495 (6.05%)\n",
      "  No Charge: 4,839 (5.32%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üîç Pickup/Dropoff Pattern (Same location?):\n",
      "  Trips with Same Pickup/Dropoff: 30,079 (33.09%)\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ NEGATIVE/ZERO FARE TRIPS ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total Negative/Zero Fare Trips: 145,516\n",
      "\n",
      "üìä Sample of Negative/Zero Fare Trips (First 20):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:01:41   2025-01-01 00:07:14            79           107           0.71        -7.20         -8.54             2                   5.55\n",
      " 2025-01-01 00:55:54   2025-01-01 01:00:38           137           233           0.69        -6.50        -11.50             4                   4.73\n",
      " 2025-01-01 00:56:12   2025-01-01 01:15:00           161           170           0.97       -16.30        -21.30             4                  18.80\n",
      " 2025-01-01 00:55:53   2025-01-01 01:06:49            79            45           1.42       -12.10        -17.10             2                  10.93\n",
      " 2025-01-01 00:29:35   2025-01-01 00:36:02            79           148           0.60        -7.20        -12.20             4                   6.45\n",
      " 2025-01-01 00:11:44   2025-01-01 00:25:41            79           161           1.88       -14.20        -19.20             4                  13.95\n",
      " 2025-01-01 00:11:58   2025-01-01 00:12:31            42            42           0.01        -3.00         -5.50             4                   0.55\n",
      " 2025-01-01 00:09:58   2025-01-01 00:14:28           140           263           0.60        -6.50        -11.50             2                   4.50\n",
      " 2025-01-01 00:50:13   2025-01-01 01:11:20            48           151           3.84       -24.00        -29.00             2                  21.12\n",
      " 2025-01-01 00:51:05   2025-01-01 00:54:12           142           239           0.92        -6.50        -11.50             2                   3.12\n",
      " 2025-01-01 00:44:03   2025-01-01 00:46:24           237           237           0.06        -4.40         -9.40             4                   2.35\n",
      " 2025-01-01 00:49:36   2025-01-01 02:11:46            68            82          24.70      -111.50       -123.44             3                  82.17\n",
      " 2025-01-01 00:32:52   2025-01-01 01:13:47            48           256           6.29       -38.70        -43.70             2                  40.92\n",
      " 2025-01-01 00:05:15   2025-01-01 00:23:39           138            24           7.79       -32.40        -48.59             4                  18.40\n",
      " 2025-01-01 00:23:53   2025-01-01 00:33:36           161           237           0.80       -10.00        -15.00             3                   9.72\n",
      " 2025-01-01 00:02:20   2025-01-01 00:03:34           249           249           0.12        -3.70         -8.70             2                   1.23\n",
      " 2025-01-01 00:16:56   2025-01-01 00:28:06           170            79           2.18       -12.80        -17.80             4                  11.17\n",
      " 2025-01-01 00:30:37   2025-01-01 01:04:46           132           225          16.70       -66.00        -70.25             4                  34.15\n",
      " 2025-01-01 00:21:30   2025-01-01 00:30:29            79            90           1.22       -10.00        -15.00             4                   8.98\n",
      " 2025-01-01 00:12:50   2025-01-01 00:14:56            88            88           0.40        -4.40         -9.40             4                   2.10\n",
      "\n",
      "üìà Negative Fare Trip Statistics:\n",
      "  Min Fare: $-900.00\n",
      "  Max Fare: $0.00\n",
      "  Average Distance: 16.53 miles\n",
      "  Average Duration: 14.56 minutes\n",
      "  Average Total Amount: $-9.13\n",
      "\n",
      "üí≥ Payment Type Distribution (Negative Fares):\n",
      "  Unknown (0): 84,861 (58.32%)\n",
      "  Dispute: 37,694 (25.90%)\n",
      "  Cash: 14,579 (10.02%)\n",
      "  No Charge: 8,280 (5.69%)\n",
      "  Credit Card: 101 (0.07%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üöï Rate Code Distribution (Negative Fares):\n",
      "  Standard: 53,888 (37.03%)\n",
      "  JFK: 3,702 (2.54%)\n",
      "  Negotiated: 1,697 (1.17%)\n",
      "  Newark: 715 (0.49%)\n",
      "  Nassau/Westchester: 460 (0.32%)\n",
      "  Unknown (99.0): 193 (0.13%)\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ OVERLAP ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Trips with BOTH zero distance AND negative/zero fare: 15,047\n",
      "\n",
      "üìä Sample of Overlapping Issues (First 10):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:07:03   2025-01-01 00:07:10           260           260           0.00        -3.00         -5.50             4                   0.12\n",
      " 2025-01-01 00:51:49   2025-01-01 00:52:20            90            90           0.00        -5.00         -8.50             4                   0.52\n",
      " 2025-01-01 00:41:17   2025-01-01 00:41:21           163           163           0.00       -70.00        -74.00             4                   0.07\n",
      " 2025-01-01 00:01:19   2025-01-01 00:01:38           164           164           0.00         0.00         -2.50             2                   0.32\n",
      " 2025-01-01 00:01:19   2025-01-01 00:01:38           164           164           0.00         0.00          2.50             2                   0.32\n",
      " 2025-01-01 00:16:11   2025-01-01 00:16:29           148           148           0.00        -3.00         -8.00             2                   0.30\n",
      " 2025-01-01 00:43:53   2025-01-01 00:44:19           142           142           0.00         0.00         -2.50             2                   0.43\n",
      " 2025-01-01 00:43:53   2025-01-01 00:44:19           142           142           0.00         0.00          2.50             2                   0.43\n",
      " 2025-01-01 00:48:58   2025-01-01 00:49:14           137           137           0.00       -28.20        -38.20             3                   0.27\n",
      " 2025-01-01 00:13:46   2025-01-01 00:14:30            65            65           0.00       -20.00        -21.00             2                   0.73\n",
      "\n",
      "\n",
      "üíæ EXPORTING ANOMALIES FOR DETAILED REVIEW\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total Zero Distance Trips: 90,893\n",
      "\n",
      "üìä Sample of Zero Distance Trips (First 20):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:49:48   2025-01-01 00:49:48            87           264           0.00        20.06         20.06             2                   0.00\n",
      " 2025-01-01 00:37:43   2025-01-01 00:37:53           148           148           0.00        12.00         17.50             1                   0.17\n",
      " 2025-01-01 00:57:08   2025-01-01 00:57:16           141           141           0.00        30.00         33.50             1                   0.13\n",
      " 2025-01-01 00:27:40   2025-01-01 00:59:30           168            76           0.00        50.50         58.94             1                  31.83\n",
      " 2025-01-01 00:56:49   2025-01-01 00:56:54           164           164           0.00        20.00         30.55             1                   0.08\n",
      " 2025-01-01 00:42:42   2025-01-01 00:42:44           261           261           0.00         3.00         10.35             1                   0.03\n",
      " 2025-01-01 00:43:22   2025-01-01 00:46:18            48            48           0.00         5.00          9.00             1                   2.93\n",
      " 2025-01-01 00:24:26   2025-01-01 00:24:34            60            60           0.00        20.00         25.20             1                   0.13\n",
      " 2025-01-01 00:14:57   2025-01-01 00:17:44            79            79           0.00         3.00          8.00             3                   2.78\n",
      " 2025-01-01 00:49:10   2025-01-01 00:49:14           143           143           0.00        85.00        115.05             1                   0.07\n",
      " 2025-01-01 00:16:07   2025-01-01 00:16:18           226           226           0.00         3.00          5.50             2                   0.18\n",
      " 2025-01-01 00:34:58   2025-01-01 01:09:03            78           139           0.00        53.50         61.94             1                  34.08\n",
      " 2025-01-01 00:22:03   2025-01-01 00:24:00           237           237           0.00         3.70         10.40             1                   1.95\n",
      " 2025-01-01 00:37:13   2025-01-01 01:26:20            49           247           0.00        40.50         42.00             1                  49.12\n",
      " 2025-01-01 00:50:01   2025-01-01 00:50:14           140           140           0.00         3.00          8.00             2                   0.22\n",
      " 2025-01-01 00:24:03   2025-01-01 00:24:06           161           161           0.00        79.00         82.50             2                   0.05\n",
      " 2025-01-01 00:26:16   2025-01-01 00:26:20           161           161           0.00        79.50         88.00             1                   0.07\n",
      " 2025-01-01 00:13:46   2025-01-01 00:29:45           234           231           0.00        13.50         22.20             1                  15.98\n",
      " 2025-01-01 00:32:18   2025-01-01 00:39:23           231           158           0.00         7.20         13.20             1                   7.08\n",
      " 2025-01-01 00:45:42   2025-01-01 01:23:00           158           262           0.00        28.90         36.90             1                  37.30\n",
      "\n",
      "üìà Zero Distance Trip Statistics:\n",
      "  Average Fare: $17.66\n",
      "  Median Fare: $13.31\n",
      "  Average Total: $23.37\n",
      "  Average Duration: 11.68 minutes\n",
      "\n",
      "üí≥ Payment Type Distribution (Zero Distance):\n",
      "  Unknown (0): 51,983 (57.19%)\n",
      "  Credit Card: 19,649 (21.62%)\n",
      "  Cash: 8,926 (9.82%)\n",
      "  Dispute: 5,495 (6.05%)\n",
      "  No Charge: 4,839 (5.32%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üîç Pickup/Dropoff Pattern (Same location?):\n",
      "  Trips with Same Pickup/Dropoff: 30,079 (33.09%)\n",
      "\n",
      "\n",
      "2Ô∏è‚É£ NEGATIVE/ZERO FARE TRIPS ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total Negative/Zero Fare Trips: 145,516\n",
      "\n",
      "üìä Sample of Negative/Zero Fare Trips (First 20):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:01:41   2025-01-01 00:07:14            79           107           0.71        -7.20         -8.54             2                   5.55\n",
      " 2025-01-01 00:55:54   2025-01-01 01:00:38           137           233           0.69        -6.50        -11.50             4                   4.73\n",
      " 2025-01-01 00:56:12   2025-01-01 01:15:00           161           170           0.97       -16.30        -21.30             4                  18.80\n",
      " 2025-01-01 00:55:53   2025-01-01 01:06:49            79            45           1.42       -12.10        -17.10             2                  10.93\n",
      " 2025-01-01 00:29:35   2025-01-01 00:36:02            79           148           0.60        -7.20        -12.20             4                   6.45\n",
      " 2025-01-01 00:11:44   2025-01-01 00:25:41            79           161           1.88       -14.20        -19.20             4                  13.95\n",
      " 2025-01-01 00:11:58   2025-01-01 00:12:31            42            42           0.01        -3.00         -5.50             4                   0.55\n",
      " 2025-01-01 00:09:58   2025-01-01 00:14:28           140           263           0.60        -6.50        -11.50             2                   4.50\n",
      " 2025-01-01 00:50:13   2025-01-01 01:11:20            48           151           3.84       -24.00        -29.00             2                  21.12\n",
      " 2025-01-01 00:51:05   2025-01-01 00:54:12           142           239           0.92        -6.50        -11.50             2                   3.12\n",
      " 2025-01-01 00:44:03   2025-01-01 00:46:24           237           237           0.06        -4.40         -9.40             4                   2.35\n",
      " 2025-01-01 00:49:36   2025-01-01 02:11:46            68            82          24.70      -111.50       -123.44             3                  82.17\n",
      " 2025-01-01 00:32:52   2025-01-01 01:13:47            48           256           6.29       -38.70        -43.70             2                  40.92\n",
      " 2025-01-01 00:05:15   2025-01-01 00:23:39           138            24           7.79       -32.40        -48.59             4                  18.40\n",
      " 2025-01-01 00:23:53   2025-01-01 00:33:36           161           237           0.80       -10.00        -15.00             3                   9.72\n",
      " 2025-01-01 00:02:20   2025-01-01 00:03:34           249           249           0.12        -3.70         -8.70             2                   1.23\n",
      " 2025-01-01 00:16:56   2025-01-01 00:28:06           170            79           2.18       -12.80        -17.80             4                  11.17\n",
      " 2025-01-01 00:30:37   2025-01-01 01:04:46           132           225          16.70       -66.00        -70.25             4                  34.15\n",
      " 2025-01-01 00:21:30   2025-01-01 00:30:29            79            90           1.22       -10.00        -15.00             4                   8.98\n",
      " 2025-01-01 00:12:50   2025-01-01 00:14:56            88            88           0.40        -4.40         -9.40             4                   2.10\n",
      "\n",
      "üìà Negative Fare Trip Statistics:\n",
      "  Min Fare: $-900.00\n",
      "  Max Fare: $0.00\n",
      "  Average Distance: 16.53 miles\n",
      "  Average Duration: 14.56 minutes\n",
      "  Average Total Amount: $-9.13\n",
      "\n",
      "üí≥ Payment Type Distribution (Negative Fares):\n",
      "  Unknown (0): 84,861 (58.32%)\n",
      "  Dispute: 37,694 (25.90%)\n",
      "  Cash: 14,579 (10.02%)\n",
      "  No Charge: 8,280 (5.69%)\n",
      "  Credit Card: 101 (0.07%)\n",
      "  Unknown: 1 (0.00%)\n",
      "\n",
      "üöï Rate Code Distribution (Negative Fares):\n",
      "  Standard: 53,888 (37.03%)\n",
      "  JFK: 3,702 (2.54%)\n",
      "  Negotiated: 1,697 (1.17%)\n",
      "  Newark: 715 (0.49%)\n",
      "  Nassau/Westchester: 460 (0.32%)\n",
      "  Unknown (99.0): 193 (0.13%)\n",
      "\n",
      "\n",
      "3Ô∏è‚É£ OVERLAP ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Trips with BOTH zero distance AND negative/zero fare: 15,047\n",
      "\n",
      "üìä Sample of Overlapping Issues (First 10):\n",
      "tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  trip_distance  fare_amount  total_amount  payment_type  trip_duration_minutes\n",
      " 2025-01-01 00:07:03   2025-01-01 00:07:10           260           260           0.00        -3.00         -5.50             4                   0.12\n",
      " 2025-01-01 00:51:49   2025-01-01 00:52:20            90            90           0.00        -5.00         -8.50             4                   0.52\n",
      " 2025-01-01 00:41:17   2025-01-01 00:41:21           163           163           0.00       -70.00        -74.00             4                   0.07\n",
      " 2025-01-01 00:01:19   2025-01-01 00:01:38           164           164           0.00         0.00         -2.50             2                   0.32\n",
      " 2025-01-01 00:01:19   2025-01-01 00:01:38           164           164           0.00         0.00          2.50             2                   0.32\n",
      " 2025-01-01 00:16:11   2025-01-01 00:16:29           148           148           0.00        -3.00         -8.00             2                   0.30\n",
      " 2025-01-01 00:43:53   2025-01-01 00:44:19           142           142           0.00         0.00         -2.50             2                   0.43\n",
      " 2025-01-01 00:43:53   2025-01-01 00:44:19           142           142           0.00         0.00          2.50             2                   0.43\n",
      " 2025-01-01 00:48:58   2025-01-01 00:49:14           137           137           0.00       -28.20        -38.20             3                   0.27\n",
      " 2025-01-01 00:13:46   2025-01-01 00:14:30            65            65           0.00       -20.00        -21.00             2                   0.73\n",
      "\n",
      "\n",
      "üíæ EXPORTING ANOMALIES FOR DETAILED REVIEW\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Exported 90,893 zero distance trips to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/zero_distance_trips.csv\n",
      "‚úÖ Exported 90,893 zero distance trips to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/zero_distance_trips.csv\n",
      "‚úÖ Exported 145,516 negative fare trips to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/negative_fare_trips.csv\n",
      "‚úÖ Exported 145,516 negative fare trips to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/negative_fare_trips.csv\n",
      "‚úÖ Exported 15,047 overlapping anomalies to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/zero_distance_and_negative_fare.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ANOMALY INVESTIGATION COMPLETE\n",
      "================================================================================\n",
      "‚úÖ Exported 15,047 overlapping anomalies to: /Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/zero_distance_and_negative_fare.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ANOMALY INVESTIGATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 10. DETAILED ANOMALY INVESTIGATION\n",
    "\n",
    "print(\"\\n\\nüî¨ DETAILED ANOMALY INVESTIGATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. ZERO DISTANCE TRIPS\n",
    "print(\"\\n1Ô∏è‚É£ ZERO DISTANCE TRIPS ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "zero_distance_trips = df[df['trip_distance'] == 0].copy()\n",
    "print(f\"\\nTotal Zero Distance Trips: {len(zero_distance_trips):,}\")\n",
    "\n",
    "print(\"\\nüìä Sample of Zero Distance Trips (First 20):\")\n",
    "columns_to_show = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID',\n",
    "                   'trip_distance', 'fare_amount', 'total_amount', 'payment_type', \n",
    "                   'trip_duration_minutes']\n",
    "print(zero_distance_trips[columns_to_show].head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà Zero Distance Trip Statistics:\")\n",
    "print(f\"  Average Fare: ${zero_distance_trips['fare_amount'].mean():.2f}\")\n",
    "print(f\"  Median Fare: ${zero_distance_trips['fare_amount'].median():.2f}\")\n",
    "print(f\"  Average Total: ${zero_distance_trips['total_amount'].mean():.2f}\")\n",
    "print(f\"  Average Duration: {zero_distance_trips['trip_duration_minutes'].mean():.2f} minutes\")\n",
    "\n",
    "print(\"\\nüí≥ Payment Type Distribution (Zero Distance):\")\n",
    "zero_payment_dist = zero_distance_trips['payment_type'].value_counts()\n",
    "payment_labels = {1: 'Credit Card', 2: 'Cash', 3: 'No Charge', 4: 'Dispute', 5: 'Unknown', 6: 'Voided'}\n",
    "for payment_id, count in zero_payment_dist.items():\n",
    "    label = payment_labels.get(payment_id, f'Unknown ({payment_id})')\n",
    "    pct = (count / len(zero_distance_trips)) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nüîç Pickup/Dropoff Pattern (Same location?):\")\n",
    "zero_distance_trips['same_location'] = zero_distance_trips['PULocationID'] == zero_distance_trips['DOLocationID']\n",
    "same_loc_count = zero_distance_trips['same_location'].sum()\n",
    "print(f\"  Trips with Same Pickup/Dropoff: {same_loc_count:,} ({(same_loc_count/len(zero_distance_trips)*100):.2f}%)\")\n",
    "\n",
    "# 2. NEGATIVE FARE TRIPS\n",
    "print(\"\\n\\n2Ô∏è‚É£ NEGATIVE/ZERO FARE TRIPS ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "negative_fare_trips = df[df['fare_amount'] <= 0].copy()\n",
    "print(f\"\\nTotal Negative/Zero Fare Trips: {len(negative_fare_trips):,}\")\n",
    "\n",
    "print(\"\\nüìä Sample of Negative/Zero Fare Trips (First 20):\")\n",
    "print(negative_fare_trips[columns_to_show].head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà Negative Fare Trip Statistics:\")\n",
    "print(f\"  Min Fare: ${negative_fare_trips['fare_amount'].min():.2f}\")\n",
    "print(f\"  Max Fare: ${negative_fare_trips['fare_amount'].max():.2f}\")\n",
    "print(f\"  Average Distance: {negative_fare_trips['trip_distance'].mean():.2f} miles\")\n",
    "print(f\"  Average Duration: {negative_fare_trips['trip_duration_minutes'].mean():.2f} minutes\")\n",
    "print(f\"  Average Total Amount: ${negative_fare_trips['total_amount'].mean():.2f}\")\n",
    "\n",
    "print(\"\\nüí≥ Payment Type Distribution (Negative Fares):\")\n",
    "neg_payment_dist = negative_fare_trips['payment_type'].value_counts()\n",
    "for payment_id, count in neg_payment_dist.items():\n",
    "    label = payment_labels.get(payment_id, f'Unknown ({payment_id})')\n",
    "    pct = (count / len(negative_fare_trips)) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nüöï Rate Code Distribution (Negative Fares):\")\n",
    "rate_labels = {1: 'Standard', 2: 'JFK', 3: 'Newark', 4: 'Nassau/Westchester', 5: 'Negotiated', 6: 'Group Ride'}\n",
    "neg_rate_dist = negative_fare_trips['RatecodeID'].value_counts()\n",
    "for rate_id, count in neg_rate_dist.items():\n",
    "    label = rate_labels.get(rate_id, f'Unknown ({rate_id})')\n",
    "    pct = (count / len(negative_fare_trips)) * 100\n",
    "    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# 3. OVERLAP ANALYSIS\n",
    "print(\"\\n\\n3Ô∏è‚É£ OVERLAP ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "zero_and_negative = df[(df['trip_distance'] == 0) & (df['fare_amount'] <= 0)]\n",
    "print(f\"\\nTrips with BOTH zero distance AND negative/zero fare: {len(zero_and_negative):,}\")\n",
    "\n",
    "if len(zero_and_negative) > 0:\n",
    "    print(\"\\nüìä Sample of Overlapping Issues (First 10):\")\n",
    "    print(zero_and_negative[columns_to_show].head(10).to_string(index=False))\n",
    "\n",
    "# 4. EXPORT ANOMALIES TO CSV FOR FURTHER INVESTIGATION\n",
    "print(\"\\n\\nüíæ EXPORTING ANOMALIES FOR DETAILED REVIEW\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "output_dir = '/Users/yash/Documents/Projects/NYC_Yellow_Taxi_Analytics/outputs/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export zero distance trips\n",
    "zero_distance_trips.to_csv(f'{output_dir}zero_distance_trips.csv', index=False)\n",
    "print(f\"‚úÖ Exported {len(zero_distance_trips):,} zero distance trips to: {output_dir}zero_distance_trips.csv\")\n",
    "\n",
    "# Export negative fare trips\n",
    "negative_fare_trips.to_csv(f'{output_dir}negative_fare_trips.csv', index=False)\n",
    "print(f\"‚úÖ Exported {len(negative_fare_trips):,} negative fare trips to: {output_dir}negative_fare_trips.csv\")\n",
    "\n",
    "# Export overlap trips\n",
    "if len(zero_and_negative) > 0:\n",
    "    zero_and_negative.to_csv(f'{output_dir}zero_distance_and_negative_fare.csv', index=False)\n",
    "    print(f\"‚úÖ Exported {len(zero_and_negative):,} overlapping anomalies to: {output_dir}zero_distance_and_negative_fare.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ANOMALY INVESTIGATION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
